{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Week 5 - Practical Workshop Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will be using `scikit-learn` again to learn more about Baselines and Decision Trees.\n",
    "### Exercise 1. \n",
    "Load the `IRIS` dataset as follows (Note that there are some small differences between this dataset and the one we were looking at last week, most notably, the errors that we needed to fix are not present):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(a)** Identify the contents of the complex data type `IRIS` , for example iris.DESCR contains a long description of the dataset, which you can `print()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "#print(iris)\n",
    "print(dir(iris))\n",
    "#print(iris.DESCR)\n",
    "#print(iris.data.shape)\n",
    "#print(iris.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(b)** The common terminology in scikit-learn is that the array defining the attribute values is called X and the array defining the “ground truth” labels is called y ; create these variables for the Iris data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(c)** Confirm that X is a 2-dimensional array, with a row for each instance and a column for each attribute. (Hint: read about the `shape` property in numpy .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (150, 4) y.shape (150,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X.shape {} y.shape {}\".format(X.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.\n",
    "Let’s build a 0-R classifier (“majority class classifier”). In scikit-learn , this is a `DummyClassifier`. \n",
    "\n",
    "**Note** `scikit-learn` uses this terminology to help remind you not to use these sorts of classifiers when trying to solve real problems; However they are easy **baseline classifiers** and are quite useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "zero_r = DummyClassifier(strategy='most_frequent')\n",
    "zero_r.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(a)** Confirm that this is a typical 0-R classifier by checking its predictions on the training data: `zero_r.predict(X)` — which class has it chosen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 50), (1, 50), (2, 50)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ybar = zero_r.predict(X)\n",
    "print(ybar)\n",
    "label_counter = Counter(y)\n",
    "label_counter.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is a number, as far as scikit-learn is concerned - so it's a little difficult to know which class label this is. On the other hand, each of the classes is equally likely, so the method appears to have chosen the \"0th\" class arbitrarily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(b)** The default evaluation metric associated with a `DummyClassifier` is `accuracy`, which you can observe using `score()` , for example: `zero_r.score(X, y)`. This strategy — building a model, and then evaluating on the data that we used to build the model — gives us something called “training accuracy”, and is generally frowned upon in the *Machine Learning* community. Why do you suppose this is? (We’ll examine some better techniques later.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333333333\n"
     ]
    }
   ],
   "source": [
    "print(zero_r.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(c)** Contrast the `0-R classifier` with the “weighted random classifier”, which makes random predictions according to the distribution of classes in the training data; (`strategy='stratified'`) — check its predictions, and evaluate its training accuracy. Does it have a higher accuracy, on average, than `0-R`, or a `lower accuracy`? (You should run `score()` at least 10 times.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32666666666666666, 0.35999999999999999, 0.34000000000000002, 0.27333333333333332, 0.34666666666666668, 0.32000000000000001, 0.32000000000000001, 0.36666666666666664, 0.29999999999999999, 0.38666666666666666]\n",
      "Average accuracy over 10 runs is: 0.33399999999999996.\n"
     ]
    }
   ],
   "source": [
    "stratified_clf = DummyClassifier(strategy='stratified')\n",
    "stratified_clf.fit(X, y)\n",
    "accuracies = []\n",
    "num_runs = 10\n",
    "for i in range(num_runs):\n",
    "    acc = stratified_clf.score(X, y)\n",
    "    accuracies.append(acc)\n",
    "print(accuracies)\n",
    "print('Average accuracy over {} runs is: {}.'.format(num_runs, np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*10 runs isn't quite enough to be certain which of these methods has greater accuracy. In fact, they will generally produce the same accuracy for class distributions where all of the classes are equally likely - but it would require more than 10 iterations to really see this.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.\n",
    "Let’s consider a couple of other classifiers: a `Decision Tree`, and `1-R` (which is really just a limited\n",
    "`DecisionTreeClassifier` in `scikit-learn` ).\n",
    "\n",
    "**NOTE:** `scikit-learn` implementation of `1-R` is slightly different to the lecture version, because it doesn’t count errors — rather it uses the **Gini coefficient** or the **Information Gain** to determine the best attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "one_r = DecisionTreeClassifier(max_depth=1)\n",
    "one_r.fit(X, y)\n",
    "dt = DecisionTreeClassifier(max_depth=None)\n",
    "dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(a)** Find the training accuracy of the two classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-R accuracy: 0.6666666666666666; DT accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "one_r_acc = one_r.score(X, y)\n",
    "dt_acc = dt.score(X, y)\n",
    "print(\"1-R accuracy: {}; DT accuracy: {}\".format(one_r_acc, dt_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Unsurprisingly, the Decision Tree makes fewer errors when testing on the training data. The fact that the DT accuracy is 100% shows that every leaf has a homogeneous class distribution.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(b)** The \"`feature_importances_`\" attribute is adequate for completely describing the 1-R classifier. Which attribute is being used to classify the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petal length (cm)\n"
     ]
    }
   ],
   "source": [
    "importances = one_r.feature_importances_\n",
    "max_index = np.argmax(importances)\n",
    "best_feature_name = iris.feature_names[max_index]\n",
    "print(best_feature_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(c)** *(Harder)* Check the predicted labels for each instance to discern the values for this attribute that each class maps to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116eb7320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ybar = one_r.predict(X)\n",
    "best_feature = X[:, max_index]\n",
    "plt.scatter(best_feature, ybar, c=ybar)\n",
    "plt.xlabel(best_feature_name)\n",
    "plt.ylabel('predicted class')\n",
    "plt.show()\n",
    "#print(ybar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Perhaps the scatter-plot above isn't the ideal way to visualise this data, but it does allow us to readily observe that small values of petal-width are labelled as class 0, and larger values as class 1.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(d)** The default splitting criterion for these Decision Trees is the **Gini coefficient**. Read up on the difference between this and the **Information Gain** — do you expect the behaviour of this model to change by using the alternative splitting criterion? Try it, and confirm your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain/entropy: 1-R accuracy: 0.6666666666666666 DT Gini accuracy: 1.0 DT IG accuracy: 1.0\n",
      "1-R attribute:  petal length (cm)\n",
      "DT Gini attribute:  petal width (cm)\n",
      "DT IG attribute:  petal length (cm)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11acc6400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_r = DecisionTreeClassifier(max_depth=1, criterion=\"entropy\")\n",
    "one_r.fit(X, y)\n",
    "dt_gini = DecisionTreeClassifier(max_depth=None) #, criterion=\"entropy\")\n",
    "dt_gini.fit(X, y)\n",
    "dt_IG = DecisionTreeClassifier(max_depth=None, criterion=\"entropy\")\n",
    "dt_IG.fit(X, y)\n",
    "\n",
    "one_r_acc = one_r.score(X, y)\n",
    "dt_gini_acc = dt_gini.score(X, y)\n",
    "dt_IG_acc = dt_gini.score(X, y)\n",
    "print(\"Information Gain/entropy: 1-R accuracy: {} DT Gini accuracy: {} DT IG accuracy: {}\".format(one_r_acc, dt_gini_acc, dt_IG_acc))\n",
    "\n",
    "importances = one_r.feature_importances_\n",
    "max_index_r = np.argmax(importances)\n",
    "best_feature_name_r = iris.feature_names[max_index_r]\n",
    "print(\"1-R attribute: \",best_feature_name_r)\n",
    "\n",
    "importances = dt_gini.feature_importances_\n",
    "max_index_dt_gini = np.argmax(importances)\n",
    "best_feature_name_dt_gini = iris.feature_names[max_index_dt_gini]\n",
    "print(\"DT Gini attribute: \",best_feature_name_dt_gini)\n",
    "\n",
    "importances = dt_IG.feature_importances_\n",
    "max_index_dt_IG = np.argmax(importances)\n",
    "best_feature_name_dt_IG = iris.feature_names[max_index_dt_IG]\n",
    "print(\"DT IG attribute: \",best_feature_name_dt_IG)\n",
    "\n",
    "ybar = one_r.predict(X)\n",
    "best_feature = X[:, max_index]\n",
    "plt.scatter(best_feature, ybar, c=ybar)\n",
    "plt.xlabel(best_feature_name)\n",
    "plt.ylabel('predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Recall that entropy is $H(X) = -\\sum p(x) \\log p(x)$; Gini is defined similarly: $G(X) = 1 - \\sum p(x)\\times p(x)$*\n",
    "\n",
    "*As we might expect from the similar formulae, whether we use the Gini coefficient or Information Gain makes little difference in this case: 1-R still chooses petal-width, and the Decision Tree still reproduces the training data exactly.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "A better mechanism for evaluating a classifier is based on randomly partitioning the data into a\n",
    "training set and test set (the “holdout” method). There is an in-built utility for this in scikit-learn ,\n",
    "but it can be in one of two places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (112, 4) X_test: (38, 4) y_train: (112,) y_test: (38,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split # Newer versions\n",
    "#from sklearn.cross_validation import train_test_split # Older versions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print('X_train: {} X_test: {} y_train: {} y_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(a)** Train the three classifiers (`0-R, 1-R, Decision Tree`) on the training data, rather than the full data set. score() is too specific to be used in most situations; another way to find the training accuracy is by comparing the predictions to the ground truth labels as follows:\n",
    "\n",
    "```python\n",
    ">>> from scikit-learn.metrics import accuracy_score\n",
    ">>> accuracy_score(zero_R.predict(X_train),y_train))\n",
    "```\n",
    "\n",
    "- Calculate the accuracy of the classifiers on the held-out training data. How does it compare to the training accuracies you calculated before? Why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracies: 0-R: 0.36607142857142855 1-R: 0.6875 DT: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "zero_r.fit(X_train, y_train)\n",
    "one_r.fit(X_train, y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "zr_acc = accuracy_score(zero_r.predict(X_train),y_train)\n",
    "or_acc = accuracy_score(one_r.predict(X_train),y_train)\n",
    "dt_acc = accuracy_score(dt.predict(X_train),y_train)\n",
    "print('Train accuracies: 0-R: {} 1-R: {} DT: {}'.format(zr_acc, or_acc, dt_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(b)** Instead of calculating the accuracy with respect to the training set, train your classifiers on the training data (using `fit()`) and then evaluate them (by calculating accuracy) according to their predictions on the test data. How different are the training accuracies and test accuracies? Hypothesise what could be causing these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracies: 0-R: 0.23684210526315788 1-R: 0.6052631578947368 DT: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "zr_acc = accuracy_score(zero_r.predict(X_test),y_test)\n",
    "or_acc = accuracy_score(one_r.predict(X_test),y_test)\n",
    "dt_acc = accuracy_score(dt.predict(X_test),y_test)\n",
    "print('Test accuracies: 0-R: {} 1-R: {} DT: {}'.format(zr_acc, or_acc, dt_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The accuracy on the test data, which we didn't use to build our models, is - perhaps unsurprisingly - somewhat worse than the accuracy on the training data.*\n",
    "\n",
    "*In the case of the Decision Tree, it is worthwhile to observe that the tree is not actually making perfect predictions, although on the whole, it is still pretty good*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(c)** By default, `train_test_split` uses 75% of the data as training, and 25% as test. This can be changed by passing an argument, for example, `test_size=0.5` means that we use 50% as training and 50% as test. Try some different values (perhaps multiple times) to see if you can observe the trade-off inherent in the model using this evaluation strategy.\n",
    "\n",
    "- **Note** The default behaviour of `train_test_split` is that the remainder of the data is used as training; this too can be altered, if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiments with test set size: 0.01\n",
      "X_train: (148, 4) X_test: (2, 4) y_train: (148,) y_test: (2,)\n",
      "Train accuracies: 0-R: 0.33783783783783783 1-R: 0.6621621621621622 DT: 1.0\n",
      "Test accuracies: 0-R: 0.0 1-R: 1.0 DT: 1.0\n",
      "\n",
      "Running experiments with test set size: 0.1\n",
      "X_train: (135, 4) X_test: (15, 4) y_train: (135,) y_test: (15,)\n",
      "Train accuracies: 0-R: 0.34814814814814815 1-R: 0.674074074074074 DT: 1.0\n",
      "Test accuracies: 0-R: 0.2 1-R: 0.6 DT: 0.9333333333333333\n",
      "\n",
      "Running experiments with test set size: 0.2\n",
      "X_train: (120, 4) X_test: (30, 4) y_train: (120,) y_test: (30,)\n",
      "Train accuracies: 0-R: 0.36666666666666664 1-R: 0.7166666666666667 DT: 1.0\n",
      "Test accuracies: 0-R: 0.2 1-R: 0.4666666666666667 DT: 0.9666666666666667\n",
      "\n",
      "Running experiments with test set size: 0.3\n",
      "X_train: (105, 4) X_test: (45, 4) y_train: (105,) y_test: (45,)\n",
      "Train accuracies: 0-R: 0.3523809523809524 1-R: 0.6761904761904762 DT: 1.0\n",
      "Test accuracies: 0-R: 0.28888888888888886 1-R: 0.6444444444444445 DT: 0.9777777777777777\n",
      "\n",
      "Running experiments with test set size: 0.4\n",
      "X_train: (90, 4) X_test: (60, 4) y_train: (90,) y_test: (60,)\n",
      "Train accuracies: 0-R: 0.36666666666666664 1-R: 0.6666666666666666 DT: 1.0\n",
      "Test accuracies: 0-R: 0.2833333333333333 1-R: 0.6666666666666666 DT: 0.9333333333333333\n",
      "\n",
      "Running experiments with test set size: 0.5\n",
      "X_train: (75, 4) X_test: (75, 4) y_train: (75,) y_test: (75,)\n",
      "Train accuracies: 0-R: 0.37333333333333335 1-R: 0.7466666666666667 DT: 1.0\n",
      "Test accuracies: 0-R: 0.29333333333333333 1-R: 0.5866666666666667 DT: 0.8933333333333333\n",
      "\n",
      "Running experiments with test set size: 0.6\n",
      "X_train: (60, 4) X_test: (90, 4) y_train: (60,) y_test: (90,)\n",
      "Train accuracies: 0-R: 0.35 1-R: 0.7 DT: 1.0\n",
      "Test accuracies: 0-R: 0.32222222222222224 1-R: 0.6444444444444445 DT: 0.9222222222222223\n",
      "\n",
      "Running experiments with test set size: 0.7\n",
      "X_train: (45, 4) X_test: (105, 4) y_train: (45,) y_test: (105,)\n",
      "Train accuracies: 0-R: 0.4 1-R: 0.7555555555555555 DT: 1.0\n",
      "Test accuracies: 0-R: 0.3047619047619048 1-R: 0.5619047619047619 DT: 0.9047619047619048\n",
      "\n",
      "Running experiments with test set size: 0.8\n",
      "X_train: (30, 4) X_test: (120, 4) y_train: (30,) y_test: (120,)\n",
      "Train accuracies: 0-R: 0.4 1-R: 0.7666666666666667 DT: 1.0\n",
      "Test accuracies: 0-R: 0.31666666666666665 1-R: 0.6416666666666667 DT: 0.9333333333333333\n",
      "\n",
      "Running experiments with test set size: 0.9\n",
      "X_train: (15, 4) X_test: (135, 4) y_train: (15,) y_test: (135,)\n",
      "Train accuracies: 0-R: 0.4666666666666667 1-R: 0.7333333333333333 DT: 1.0\n",
      "Test accuracies: 0-R: 0.31851851851851853 1-R: 0.6370370370370371 DT: 0.9407407407407408\n",
      "\n",
      "Running experiments with test set size: 0.99\n",
      "X_train: (1, 4) X_test: (149, 4) y_train: (1,) y_test: (149,)\n",
      "Train accuracies: 0-R: 1.0 1-R: 1.0 DT: 1.0\n",
      "Test accuracies: 0-R: 0.3288590604026846 1-R: 0.3288590604026846 DT: 0.3288590604026846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_size in [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]:\n",
    "    print('Running experiments with test set size: {}'.format(test_size))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    print('X_train: {} X_test: {} y_train: {} y_test: {}'.format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
    "    \n",
    "    zero_r.fit(X_train, y_train)\n",
    "    one_r.fit(X_train, y_train)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    zr_acc = accuracy_score(zero_r.predict(X_train),y_train)\n",
    "    or_acc = accuracy_score(one_r.predict(X_train),y_train)\n",
    "    dt_acc = accuracy_score(dt.predict(X_train),y_train)\n",
    "    print('Train accuracies: 0-R: {} 1-R: {} DT: {}'.format(zr_acc, or_acc, dt_acc))\n",
    "\n",
    "    zr_acc = accuracy_score(zero_r.predict(X_test),y_test)\n",
    "    or_acc = accuracy_score(one_r.predict(X_test),y_test)\n",
    "    dt_acc = accuracy_score(dt.predict(X_test),y_test)\n",
    "    print('Test accuracies: 0-R: {} 1-R: {} DT: {}'.format(zr_acc, or_acc, dt_acc))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You might need to run this more than once to see how drastically the performance can change on the smaller test sets. For the larger test sets, the performance is rather consistent (in the sense that it is usually bad), but there isn't quite enough training data to build an accurate model.*\n",
    "\n",
    "*We might also note that the training accuracy is almost better than the test accuracy for these classifiers; this is yet another reason to be suspicious of training accuracy (as it tends to **over-estimate** the **true performance** of our classifier).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.\n",
    "*(Stratified)* `M–fold` cross-validation is so popular, `scikit-learn` has a utility that applies it directly.\n",
    "For example, 10–fold cross-validation of the `0-R` classifier proceeds as follows:\n",
    "\n",
    "```python\n",
    ">>> from sklearn.model_validation import cross_val_score # Newer versions\n",
    ">>> from sklearn.cross_validation import cross_val_score # Older versions\n",
    ">>> cross_val_score(zero_R, X, y, cv=10)\n",
    "```\n",
    "**Note:** There are also simpler methods like `StratifiedKFold()` to generate the partitions, which you can then use to train and test the model yourself, if you wish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(a)** This method returns an array of the calculated evaluation metric (by default, accuracy) across the folds. Write a wrapper function which averages these values, so as to come up with a single score for the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33333333  0.33333333  0.33333333  0.33333333  0.33333333  0.33333333\n",
      "  0.33333333  0.33333333  0.33333333  0.33333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(zero_r, X, y, cv=10))\n",
    "\n",
    "def avg_score(clf, X, y, cv=10):\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    return np.mean(scores)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(b)** How does the estimate of the accuracy of the various classifiers using cross-validation compare to the training accuracies and holdout accuracies you calculated above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier(constant=None, random_state=None, strategy='most_frequent')\n",
      "Average CV accuracy 0.333333333333\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=1,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Average CV accuracy 0.666666666667\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "Average CV accuracy 0.953333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in [zero_r, one_r, dt]:\n",
    "    avg = avg_score(clf, X, y, cv=10)\n",
    "    print(clf)\n",
    "    print('Average CV accuracy', avg)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interestingly, for our baseline classifiers, the CV accuracy is very much like the training accuracy - this occurs because of stratification. Arguably, holdout can be a little unfair for these methods because the class distribution can be different between the training and test sets, simply due to random chance.*\n",
    "\n",
    "*As for the Decision Tree, the CV accuracy looks fairly similar to the test accuracy for many of the holdout split sizes. The main advantage is that this value doesn't tend to change quite as much as holdout test accuracy, if we repeat the procedure. A secondary advantage is that we don't need to try to justify why some particular holdout split size is appropriate - stratified 10-fold CV is just a \"standard\" strategy.*\n",
    "\n",
    "*However, there are some trade-offs that might be considered when choosing the split size. Like in hold-out startegy we still need a balance between speed and having as many training examples as possible per split (10-fold is great for models that train quickly, but if training takes days I would tend to use 5-fold or less)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
