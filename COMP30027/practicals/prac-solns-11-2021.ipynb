{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Week 11 - Practical Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:  You will need the newer (18.1) build of `scikit-learn` for its neural network support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 1.\n",
    "The Multilayer Perceptron is available from (newer builds of) `scikit-learn` as `sklearn.neural_network.MLPClassifier`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.(a) \n",
    "Build a default Multilayer Perceptron to classify the `Iris` data. Evaluate its cross-validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (150, 4) y: {0, 1, 2}\n",
      "corss-val acc: 0.9866666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=2000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print('X:', X.shape, 'y:', set(y))\n",
    "\n",
    "\n",
    "clf = MLPClassifier(max_iter=2000)\n",
    "\n",
    "print('corss-val acc:', np.mean(cross_val_score(clf, X, y, cv=5)))\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.(b) \n",
    "Check the `coefs_` and `n_layers_` attributes of the fitted classifier to examine the resulting neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.66718038e-01,  3.88247175e-01, -6.15693510e-02,\n",
      "         5.79906789e-01, -4.35990579e-02,  5.04288895e-02,\n",
      "        -1.90279648e-01,  6.71765998e-01, -6.95615506e-02,\n",
      "         1.28235058e-01],\n",
      "       [ 1.50653818e-01,  4.13385199e-02,  2.24216036e-02,\n",
      "         9.79004094e-01, -9.55817039e-02, -4.91173544e-01,\n",
      "         1.83898936e-02, -4.23969816e-01, -1.80312634e-01,\n",
      "         1.17055071e-01],\n",
      "       [-3.29298310e-01, -4.90696148e-01, -4.07649037e-03,\n",
      "        -8.08397568e-01,  5.05216225e-06,  7.24227623e-01,\n",
      "         2.53221120e-02, -5.88011125e-01, -2.71407286e-02,\n",
      "         7.54511339e-01],\n",
      "       [ 6.03154447e-01, -4.28797783e-01,  8.96386201e-02,\n",
      "        -8.76669929e-01, -3.86065952e-06,  1.97945034e-01,\n",
      "         7.37566983e-02, -1.68779330e-01, -2.48014333e-02,\n",
      "        -3.49660796e-02]]), array([[ 1.79203342e-02, -1.06248373e-02,  5.50521381e-01,\n",
      "        -2.07344564e-01,  3.90209148e-01, -1.85515280e-01,\n",
      "         3.86661993e-01,  3.49371971e-01, -6.89183338e-04,\n",
      "        -2.79218988e-01],\n",
      "       [ 5.71373264e-01,  2.01641112e-05,  1.24080907e+00,\n",
      "        -1.26980060e-01, -7.08467041e-01,  1.27713191e+00,\n",
      "         6.68522482e-01, -2.76777310e-01, -1.33773836e-02,\n",
      "         9.04288156e-01],\n",
      "       [ 2.65092579e-02,  1.99687569e-02,  7.15227754e-03,\n",
      "         4.61706972e-05, -1.08368140e-03, -7.83310176e-03,\n",
      "         2.28491536e-03,  3.39980733e-04,  2.57290063e-02,\n",
      "        -1.16827290e-02],\n",
      "       [ 6.11736593e-01, -1.19548572e-02,  7.54600050e-01,\n",
      "        -6.86322961e-03,  4.13887637e-02,  5.28369313e-01,\n",
      "         6.12326669e-01, -2.11273760e-01, -5.97567768e-03,\n",
      "         4.24163032e-01],\n",
      "       [ 2.37869438e-03,  6.67147601e-02,  3.37853254e-02,\n",
      "        -2.28078408e-03, -3.28476644e-04, -3.65722514e-02,\n",
      "        -1.60471534e-03,  1.19927395e-02, -5.01132213e-02,\n",
      "         1.83699723e-02],\n",
      "       [-2.63261770e-01, -7.00416893e-03, -8.24888256e-01,\n",
      "         4.53701913e-01,  8.48575366e-01,  4.17446873e-01,\n",
      "        -1.05394726e-01, -2.56939581e-01, -1.77607529e-04,\n",
      "        -1.02057427e+00],\n",
      "       [ 1.01999978e-03, -6.09046267e-02, -1.26154169e-02,\n",
      "        -3.97450907e-03, -6.25745496e-02,  2.52632227e-02,\n",
      "         1.19590515e-01,  4.24696011e-04,  3.21900746e-02,\n",
      "         3.94775449e-02],\n",
      "       [ 1.89953589e-01,  1.55624562e-03, -1.66081086e-02,\n",
      "         4.34289880e-01, -1.29990351e-01,  5.18986664e-01,\n",
      "         3.99739741e-01,  3.38972976e-01, -6.30465718e-02,\n",
      "         5.59774545e-01],\n",
      "       [-6.07380339e-02, -4.13077130e-04,  5.02396192e-03,\n",
      "        -7.65971945e-04, -3.81460029e-03,  5.45383777e-04,\n",
      "        -1.54705521e-03,  5.60857154e-02,  7.57812045e-03,\n",
      "         2.03553014e-02],\n",
      "       [-3.31871321e-01, -1.40866374e-02,  2.04285812e-01,\n",
      "         2.63388106e-01,  5.85776553e-01, -2.36749477e-01,\n",
      "        -1.78109645e-01, -5.40452722e-01, -3.07932288e-04,\n",
      "         2.36524714e-01]]), array([[ 9.11244424e-01, -8.82286397e-01, -3.75440475e-01],\n",
      "       [ 6.05728793e-02, -1.63139882e-03,  3.79817332e-04],\n",
      "       [ 3.53838305e-01,  6.69356491e-01, -2.95409538e-01],\n",
      "       [-8.49472154e-01,  5.08731067e-01,  2.06871346e-02],\n",
      "       [-1.82380972e-01, -1.43513665e-01,  5.87336532e-01],\n",
      "       [-3.97645152e-01,  5.53495572e-01, -1.01724310e+00],\n",
      "       [-3.96821643e-01,  3.18655182e-01, -6.54264987e-01],\n",
      "       [-3.83263875e-01,  4.19678455e-01,  3.18996692e-01],\n",
      "       [-2.10700447e-03,  4.17308233e-03, -7.11693576e-02],\n",
      "       [ 1.01905157e+00, -1.01173870e+00, -4.74980587e-02]])]\n",
      "parameter shapes: [(4, 10), (10, 10), (10, 3)]\n",
      "num layers: 4\n"
     ]
    }
   ],
   "source": [
    "print(clf.coefs_)\n",
    "print('parameter shapes:',[p.shape for p in clf.coefs_])\n",
    "print('num layers:', clf.n_layers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.\n",
    "One important issue with this Multilayer Perceptron is that it is sensitive to the scale of the input attribute values.\n",
    "### Exercise 2.(a) \n",
    "Read up on the `StandardScaler` , and re-scale the `Iris` data so that each attribute has a *mean* of 0 and a *variance* of 1. Evaluate and examine the resulting neural network built on the re-scaled data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corss-val cheating standardised features acc: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "clf = MLPClassifier(max_iter=2000)\n",
    "#it is cheating because the mean and variance are estimated using both training and test data\n",
    "print('corss-val cheating standardised features acc:', np.mean(cross_val_score(clf, scaler.fit_transform(X), y, cv=5))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.(c) \n",
    "(Harder) Calculating the _mean_ and _variance_ on the entire data set (before splitting into train/test sets) is cheating slightly. Write a re-scale function that calculates the scaling factors for the training data, and applies the scaler to the test data. Then, write a wrapper function that uses this to cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corss-val noncheating standardised features acc: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(max_iter=2000)\n",
    "#this way we don't cheat read more on pipelines https://scikit-learn.org/stable/modules/compose.html\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])\n",
    "print('corss-val noncheating standardised features acc:', np.mean(cross_val_score(pipeline, X, y, cv=5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You might not see reduction in performance for the noncheating method, but in general it is best to standardise only the training data (fit_transform), and then apply the transformation to the test data (transform).*\n",
    "\n",
    "*Also you didn't see improvements with standardisation, which might be the result of the neural network not being tuned well in terms of regularisation, and number/size of the layers.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 \n",
    "You can coerce the Multilayer Perceptron to have specifically–sized hidden layers using the *hidden_layer_sizes* parameter.\n",
    "### Exercise 3.(a) \n",
    "Train a Multilayer Perceptron on the two-class `Abalone` data, and examine the resulting neural\n",
    "network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (4177, 7) y: {0, 1}\n",
      "[array([[ 3.52572688e-001, -1.23919665e-001,  3.42827444e-001,\n",
      "        -4.92489901e-002,  3.61520912e-001,  3.03376111e-001,\n",
      "        -1.08845783e-001,  2.15759509e-001,  7.83537638e-006,\n",
      "        -1.49217546e-001, -7.89495359e-002,  1.16375903e-001,\n",
      "        -1.82286447e-001,  2.78605252e-145, -2.94521679e-001,\n",
      "         1.81483691e-001, -1.01313416e-158,  3.10248577e-001,\n",
      "        -2.93549303e-160, -4.56630795e-141, -1.49350241e-178,\n",
      "        -3.42014059e-002, -3.75905327e-001,  1.00452307e-001,\n",
      "         3.61646417e-001, -9.32571047e-002,  3.33744542e-001,\n",
      "         4.81296718e-002, -3.21699808e-001,  5.74118266e-143,\n",
      "        -6.79989459e-155,  8.41724209e-002,  3.34750452e-001,\n",
      "        -5.18586062e-177,  7.93962566e-007,  3.31397062e-001,\n",
      "         1.00345517e-001, -1.88890983e-001,  3.12171001e-001,\n",
      "        -1.51902774e-001,  7.64060414e-002, -6.14498822e-002,\n",
      "         7.94123030e-002,  6.68564925e-002, -8.84254741e-002,\n",
      "         3.21908409e-171,  1.19866498e-001,  1.16002463e-001,\n",
      "         1.56732039e-001, -3.64323456e-004,  5.01823833e-002,\n",
      "        -1.74326324e-002, -3.50255533e-001, -8.90155298e-141,\n",
      "        -4.80243853e-002, -1.78345374e-001,  1.43862546e-001,\n",
      "         6.43980787e-002, -8.39569165e-002,  2.47837956e-001,\n",
      "         1.74502730e-001, -5.95431690e-003, -2.14356712e-173,\n",
      "         1.32768374e-158,  1.79768701e-001, -1.21328892e-001,\n",
      "         3.75232255e-001,  3.80637830e-001, -2.25066807e-001,\n",
      "        -1.87580526e-002,  1.11066838e-001, -6.86548845e-002,\n",
      "        -1.39855565e-001,  8.12357594e-003, -2.65619766e-001,\n",
      "        -7.79849791e-002, -2.20802309e-017,  1.06504287e-001,\n",
      "        -1.48797174e-003,  2.07536210e-166, -1.67795253e-001,\n",
      "         2.26566576e-166,  5.25089048e-003, -1.68436096e-152,\n",
      "        -3.82800934e-178, -3.83817959e-002,  1.07468488e-002,\n",
      "        -2.05227058e-001, -5.52987187e-157,  2.15664826e-002,\n",
      "         4.08828441e-001,  8.41036098e-002,  1.52484986e-001,\n",
      "         5.21842262e-002,  6.55379254e-002,  2.07374865e-001,\n",
      "         3.45015355e-002,  1.83068108e-001, -1.79466829e-001,\n",
      "        -5.04816891e-002],\n",
      "       [ 4.42283423e-002, -1.08867107e-001,  6.83522856e-002,\n",
      "         1.78264854e-002,  4.78051447e-002,  1.98844299e-001,\n",
      "        -8.32706335e-003,  3.87844906e-001, -3.76615767e-008,\n",
      "        -2.75024378e-002, -2.45233630e-001, -2.53535429e-002,\n",
      "        -1.28977660e-001, -9.50277163e-175,  1.15447208e-001,\n",
      "        -9.79897192e-002,  2.68676881e-147,  5.73549738e-002,\n",
      "         1.97030838e-177, -9.84681756e-164,  1.82964960e-175,\n",
      "        -1.01837965e-001,  1.65172678e-001,  1.29450431e-002,\n",
      "         6.61711838e-002,  1.81476856e-001,  2.71845659e-002,\n",
      "         5.54743302e-003,  1.46986128e-001, -5.29637629e-143,\n",
      "        -2.71384138e-146,  2.23179249e-001,  8.38890088e-002,\n",
      "         1.00631928e-169,  1.91058702e-008,  1.74638690e-001,\n",
      "         2.25509099e-001, -7.15958762e-002,  1.24295554e-001,\n",
      "         1.24601971e-001, -2.18384453e-001,  1.52490665e-001,\n",
      "         6.95402061e-002,  9.12599896e-002, -5.45470876e-003,\n",
      "         2.80455132e-166, -6.69824359e-002, -8.76605409e-002,\n",
      "        -6.88690847e-002,  1.37818077e-004,  1.88769322e-002,\n",
      "         2.26086388e-001,  1.30551355e-001,  1.16049936e-174,\n",
      "         2.78779492e-001,  1.87011310e-001,  1.38188795e-001,\n",
      "        -1.33236091e-001, -2.59782674e-001,  1.33313640e-001,\n",
      "         1.41309136e-001,  1.30375963e-003, -1.83490249e-180,\n",
      "        -9.04143598e-168,  5.18168974e-002,  3.15772693e-001,\n",
      "         2.55276735e-001,  2.81487308e-001, -9.30663446e-003,\n",
      "        -1.47737896e-001,  1.74085741e-002,  9.54659344e-002,\n",
      "        -5.28652621e-002,  5.32064434e-002,  9.67415582e-002,\n",
      "         1.10892734e-001, -8.62776426e-021,  1.99092746e-001,\n",
      "         2.77237994e-004,  1.18578234e-170,  3.97316287e-002,\n",
      "         1.14082077e-157,  1.06834214e-001, -5.35506184e-148,\n",
      "        -1.36588146e-135,  6.40490293e-002,  8.75759626e-003,\n",
      "         2.08678757e-001, -4.53783760e-177,  1.25272133e-001,\n",
      "        -1.74789607e-001, -2.32667856e-001, -1.02753906e-001,\n",
      "         1.45671470e-001,  2.24926097e-001,  1.56230207e-001,\n",
      "         3.05319147e-001,  5.37974412e-002,  2.74366550e-001,\n",
      "         2.15932704e-001],\n",
      "       [ 9.14919294e-002,  1.18935476e-001, -3.72891766e-001,\n",
      "        -7.91038896e-001,  7.12553204e-002, -2.63265047e-001,\n",
      "         6.48789234e-002,  5.71690008e-001, -9.99104134e-080,\n",
      "        -1.00432443e-003, -8.46115426e-001,  6.50355989e-003,\n",
      "        -9.60589951e-002, -4.34689297e-162,  2.46653361e-001,\n",
      "         1.55491246e-001,  4.01571126e-160,  1.21171769e-001,\n",
      "        -2.87581611e-166,  5.37739329e-163, -1.04494103e-169,\n",
      "         1.22519679e-001,  2.08825989e-001, -7.40540479e-002,\n",
      "        -9.42954871e-003,  2.03510725e-001, -3.86688337e-001,\n",
      "         2.25457454e-001,  1.28571823e-001, -4.75973783e-177,\n",
      "        -1.19019439e-153,  2.77340319e-001,  1.42608504e-002,\n",
      "         5.01500830e-165,  1.23792898e-003, -6.08420757e-001,\n",
      "        -4.97263834e-001, -4.85180143e-002,  3.55537003e-002,\n",
      "         3.31541881e-001,  2.51195602e-001, -7.07917346e-002,\n",
      "        -1.18417128e-001,  1.43116025e-001,  1.54106003e-001,\n",
      "        -9.50627539e-152, -6.68012642e-001,  3.19747142e-003,\n",
      "        -1.60760383e-001,  5.88884778e-003,  2.33538302e-001,\n",
      "         1.29107403e-001,  2.30965334e-002, -6.88190371e-152,\n",
      "         9.58155285e-002,  1.48392100e-001, -5.50012787e-001,\n",
      "         1.29753680e-001, -8.11831440e-004, -5.80199281e-001,\n",
      "        -2.72771447e-001,  2.54748915e-002,  2.74306163e-150,\n",
      "         2.14737141e-161,  3.79917488e-001,  6.07131812e-002,\n",
      "        -1.94951981e-002,  2.16498759e-001,  1.68909541e-001,\n",
      "         1.64186583e-001, -5.73814205e-001, -1.07498660e-001,\n",
      "        -6.09750847e-003,  1.34169102e-001,  2.67985126e-001,\n",
      "        -5.43233279e-001,  1.29679035e-048,  8.15016920e-002,\n",
      "         2.59306547e-002, -1.80791918e-168,  2.06057836e-002,\n",
      "        -5.42133812e-146, -9.56206645e-002,  3.28034945e-148,\n",
      "         2.73992049e-148,  4.55082937e-002,  2.33601394e-001,\n",
      "         2.66341131e-001,  6.92675724e-160, -6.28484453e-002,\n",
      "        -4.80489844e-001,  2.28912800e-002,  3.16875934e-001,\n",
      "        -1.43052169e-001, -4.65368283e-001, -1.20583562e-001,\n",
      "         2.40666736e-002, -7.31981520e-001, -7.18821622e-002,\n",
      "        -2.60085735e-002],\n",
      "       [-2.75862870e-001, -2.47971090e-001,  1.57410399e-001,\n",
      "        -3.21998710e-001, -3.03106643e-001, -2.39329521e-001,\n",
      "         5.45396581e-002, -2.33876063e-001, -1.20499706e-011,\n",
      "         2.86197390e-003, -2.48495110e-001, -1.86838815e-001,\n",
      "        -6.99062049e-002,  3.74256921e-142,  3.62126587e-001,\n",
      "        -2.78949139e-001, -2.39270466e-174,  7.79871945e-002,\n",
      "        -4.53480024e-147, -5.22434327e-148, -4.04937156e-157,\n",
      "         3.34782465e-001,  3.91836817e-001, -1.29913209e-001,\n",
      "        -2.44541234e-001,  3.22743257e-001, -2.98795863e-001,\n",
      "         4.34917359e-001,  3.44552371e-001, -9.88170238e-140,\n",
      "        -2.28592608e-178,  2.60803914e-001, -1.30633942e-001,\n",
      "        -5.25322791e-152, -2.97095978e-005, -1.50450866e-001,\n",
      "        -3.04579645e-001, -1.69916662e-001, -1.08117829e-001,\n",
      "         2.32976860e-001, -1.08931501e-001, -1.25175011e-001,\n",
      "        -1.14942756e-001,  2.95985308e-001,  3.51959647e-001,\n",
      "         4.93310763e-158, -1.40469853e-001, -2.57011868e-002,\n",
      "        -2.06688925e-002, -9.62025813e-004,  2.24972155e-001,\n",
      "         4.69857668e-001,  4.37196069e-001,  6.96096783e-151,\n",
      "         4.47681187e-001,  4.02801718e-001, -3.47929873e-001,\n",
      "        -2.58338933e-001,  1.32700380e-001, -3.56423520e-001,\n",
      "        -3.75483094e-001, -5.18668062e-003,  5.95823577e-175,\n",
      "         6.08236225e-178,  4.00822619e-001,  4.23065881e-001,\n",
      "        -3.77409531e-001, -5.05079076e-002,  4.85573439e-001,\n",
      "        -1.35989859e-001, -3.39037238e-001,  3.80282165e-002,\n",
      "         1.22194567e-001,  2.46723472e-001,  4.60711719e-001,\n",
      "         2.49415112e-002,  6.37910953e-008, -1.11736930e-001,\n",
      "        -3.50861553e-003, -3.40794572e-178, -3.98209719e-002,\n",
      "         1.08451005e-163, -5.05981132e-002, -3.34855909e-162,\n",
      "         2.68632794e-153, -1.37453406e-001,  4.08832822e-001,\n",
      "         4.04176322e-001, -9.93172109e-164, -5.21809070e-002,\n",
      "        -2.80042381e-001,  2.05625139e-002,  1.41771263e-001,\n",
      "        -2.29231074e-002, -2.33073089e-001, -2.19098805e-001,\n",
      "         2.99921152e-001, -3.52140660e-001,  4.72701782e-001,\n",
      "         2.41524753e-001],\n",
      "       [ 1.91772250e-001,  7.87842274e-001,  4.16008112e-001,\n",
      "         7.84984683e-001,  2.94256260e-001,  3.57917110e-001,\n",
      "         2.98062289e-003, -1.46502391e+000, -1.22158545e-022,\n",
      "        -6.78335006e-004,  6.92360374e-001,  5.40349531e-001,\n",
      "         6.62074641e-002, -5.23666929e-167, -4.65878733e-001,\n",
      "         3.59456919e-001, -2.01835801e-172,  5.68002412e-001,\n",
      "        -9.86520627e-165, -2.79778624e-175,  2.13358401e-144,\n",
      "        -5.12609643e-001, -5.32648227e-001,  3.03122225e-001,\n",
      "         1.44238226e-001, -1.27149953e-001,  4.82267479e-001,\n",
      "        -3.75601141e-001, -2.20936279e-001,  4.16320845e-161,\n",
      "         1.07157051e-175, -2.80288051e-001,  2.41451025e-001,\n",
      "         1.83833910e-174, -1.61199272e-008,  1.83065391e-001,\n",
      "         2.87206746e-001,  2.56685431e-003,  6.74330659e-001,\n",
      "        -1.35758844e-001,  4.31475378e-001,  5.17817201e-001,\n",
      "         4.27666764e-001, -2.09923982e-001, -1.58870316e-001,\n",
      "        -1.09752595e-159,  4.14905154e-001, -2.85405290e-003,\n",
      "         3.55898308e-001,  3.69857530e-006, -5.08044937e-001,\n",
      "        -5.36987502e-001, -4.03923299e-001,  8.91142280e-158,\n",
      "        -4.29780597e-001, -6.44874274e-002,  7.42919796e-001,\n",
      "         5.73778662e-001, -1.37579535e-002,  5.60077724e-001,\n",
      "         5.80978150e-001, -1.25561550e-003, -6.89068021e-176,\n",
      "        -1.41616368e-137, -4.00017435e-001, -4.68426202e-001,\n",
      "         2.93466467e-001,  5.30724368e-001, -1.70781440e-001,\n",
      "         5.73228240e-001,  3.75359618e-001,  8.27182814e-002,\n",
      "        -2.29595199e-001,  6.06645091e-001, -2.40739542e-001,\n",
      "         3.03722657e-001, -1.69080661e-014,  2.42230403e-002,\n",
      "        -1.14538367e-004, -9.33601403e-158,  1.42142707e-001,\n",
      "         1.04226632e-175,  1.90705913e-001, -6.44879900e-174,\n",
      "        -2.27605104e-155,  7.93156649e-003, -1.07859088e-001,\n",
      "        -5.47701112e-001, -2.46962332e-168, -2.03269236e-001,\n",
      "         6.62723755e-001,  1.11026907e-001,  5.65097828e-001,\n",
      "         4.76160111e-001,  5.39557863e-001,  1.21742257e-001,\n",
      "        -1.16549499e-001,  7.70534282e-001, -4.91847277e-001,\n",
      "        -8.01861931e-002],\n",
      "       [ 4.13250692e-002, -5.94542650e-001,  1.34190850e-001,\n",
      "        -2.72872476e-001,  1.03067961e-001, -9.62520253e-002,\n",
      "         7.46792458e-002, -2.54377152e-001,  2.29890198e-042,\n",
      "        -3.56501730e-005, -1.09299455e-001,  1.65198353e-001,\n",
      "        -5.82884198e-002,  3.93441080e-164,  1.30951362e-001,\n",
      "        -1.82639219e-002,  4.05446926e-149,  3.30841907e-001,\n",
      "        -3.72430910e-135, -3.74850538e-164,  8.90823182e-173,\n",
      "        -2.61509186e-001, -2.18907674e-002, -6.77180105e-002,\n",
      "         1.08240929e-001, -3.80999049e-001,  1.58660137e-001,\n",
      "        -2.87019729e-001, -1.38301476e-001, -4.07820851e-175,\n",
      "        -8.27048282e-177,  5.81065135e-002, -2.83289357e-002,\n",
      "        -1.01496258e-176, -1.35291509e-020,  5.36392276e-002,\n",
      "         3.87197747e-001, -1.59853850e-002,  3.12595539e-001,\n",
      "        -3.14971955e-002, -1.98037903e-001,  6.54211001e-002,\n",
      "        -9.51626298e-002,  9.80860392e-003,  4.76973587e-002,\n",
      "         4.24919886e-170, -6.83964806e-002,  8.69742969e-004,\n",
      "         1.82689619e-001, -2.36019850e-011, -4.56754389e-002,\n",
      "        -1.78182353e-001,  1.10180462e-001, -1.31923542e-138,\n",
      "        -1.09982032e-002, -1.31718439e-001, -2.67068597e-001,\n",
      "         1.54538589e-001,  9.04381492e-002,  1.30194311e-001,\n",
      "        -4.01423085e-002, -3.77503131e-008,  7.03324627e-166,\n",
      "        -6.12955451e-142, -2.45194088e-001, -2.67504685e-001,\n",
      "         1.42839407e-001,  2.67971251e-001,  1.97781552e-003,\n",
      "         5.74936460e-002,  4.72198577e-001, -3.18596342e-002,\n",
      "         1.49366310e-001,  3.44950729e-001, -3.04686067e-001,\n",
      "        -1.59762194e-001, -6.34428215e-026, -8.89272132e-002,\n",
      "        -1.40213591e-009, -1.79216310e-137,  3.14777645e-002,\n",
      "        -2.42302188e-170,  3.17169918e-001, -1.17924284e-135,\n",
      "         1.33400015e-153, -3.52264339e-002, -2.20193691e-001,\n",
      "        -1.46044916e-001,  1.63936400e-173,  4.05891975e-002,\n",
      "         1.38144869e-001,  8.87588865e-004,  2.03970826e-001,\n",
      "        -1.50836009e-001, -7.05343224e-002,  2.56690250e-001,\n",
      "        -3.51238231e-002, -3.84286959e-001,  1.19141228e-001,\n",
      "        -1.51786264e-001],\n",
      "       [-3.84106541e-001, -8.99870278e-001, -1.99920217e-001,\n",
      "        -6.21926721e-001, -5.38931599e-001, -1.38869561e-001,\n",
      "        -4.44134605e-003,  5.44492547e-001,  1.99664143e-006,\n",
      "        -1.33948289e-004, -5.91110146e-001, -1.28456184e-001,\n",
      "         4.55630616e-002,  6.44027623e-151,  4.43552072e-001,\n",
      "        -2.08912207e-001,  2.57647252e-170,  1.09817190e-001,\n",
      "         6.38567223e-139, -9.42198162e-140, -1.19868790e-138,\n",
      "         3.67887290e-001,  5.40194696e-001, -4.18230799e-001,\n",
      "        -1.75338979e-001,  1.17403532e-001, -6.49551270e-001,\n",
      "         2.67426360e-001,  1.23248125e-001,  9.28846251e-152,\n",
      "         8.74184011e-156,  2.09174186e-001, -5.98662380e-001,\n",
      "        -3.67946905e-169,  3.01630303e-017, -3.42113215e-001,\n",
      "        -3.97692383e-001, -1.97264073e-002, -3.23664672e-001,\n",
      "         3.21987000e-001, -7.71723134e-001, -4.52104716e-001,\n",
      "        -1.11549453e-001,  1.96584367e-001,  2.94383460e-001,\n",
      "         9.11247649e-175, -6.59159516e-001, -1.85872813e-003,\n",
      "        -5.48600114e-001, -1.40451541e-009,  3.70521009e-001,\n",
      "         5.43301200e-001,  2.94276191e-001, -3.36622088e-172,\n",
      "         5.49695811e-001,  5.27508808e-001, -7.90193902e-001,\n",
      "        -3.35277104e-001,  7.35714280e-002, -5.75997101e-001,\n",
      "        -4.18221308e-001, -1.72963914e-006, -1.46255301e-162,\n",
      "         9.48863602e-152,  2.35483584e-001,  2.01289650e-001,\n",
      "        -3.26232091e-001, -2.30391955e-001,  4.37875211e-001,\n",
      "        -4.26630911e-001, -1.94169939e-001, -2.37803759e-002,\n",
      "         5.00861277e-002, -1.49166897e-001,  3.68007770e-001,\n",
      "        -1.01594750e-001,  9.94692896e-018, -1.97781391e-001,\n",
      "         2.91332732e-006, -7.57671485e-142,  1.21460679e-001,\n",
      "         1.95240641e-164, -3.23771554e-001,  3.70685253e-155,\n",
      "         2.34169078e-169, -3.25432095e-002,  3.83855531e-001,\n",
      "         2.41187200e-001, -3.24548447e-142, -7.20077987e-002,\n",
      "        -2.85004623e-001, -1.97342563e-002, -2.20489204e-001,\n",
      "        -6.17310862e-002, -8.39392112e-001, -1.36226384e-001,\n",
      "         2.63201260e-001, -6.84070530e-001,  5.04969386e-001,\n",
      "         5.09566079e-001]]), array([[-4.40950027e-001],\n",
      "       [-1.96875718e+000],\n",
      "       [-4.35232966e-001],\n",
      "       [-2.71326789e+000],\n",
      "       [-5.93582599e-001],\n",
      "       [-3.20091155e-001],\n",
      "       [-9.48790255e-002],\n",
      "       [ 2.78076666e+000],\n",
      "       [-8.33687662e-120],\n",
      "       [ 2.35007577e-002],\n",
      "       [-1.34458387e+000],\n",
      "       [-2.68785900e-001],\n",
      "       [ 1.08664832e-002],\n",
      "       [ 2.45245167e-139],\n",
      "       [ 4.78256329e-001],\n",
      "       [-6.23706430e-001],\n",
      "       [ 4.54678015e-167],\n",
      "       [-3.91380067e-001],\n",
      "       [ 1.00433691e-170],\n",
      "       [ 4.61289117e-168],\n",
      "       [ 2.38550066e-159],\n",
      "       [ 4.73848972e-001],\n",
      "       [ 6.80261588e-001],\n",
      "       [-3.97819828e-001],\n",
      "       [-5.21152317e-001],\n",
      "       [ 1.26345622e-001],\n",
      "       [-1.43006603e+000],\n",
      "       [ 3.29815994e-001],\n",
      "       [ 4.17075325e-001],\n",
      "       [ 3.53919704e-160],\n",
      "       [-2.70849077e-155],\n",
      "       [ 3.42317137e-001],\n",
      "       [-2.42005157e-001],\n",
      "       [-5.58899550e-148],\n",
      "       [ 4.06191166e-019],\n",
      "       [-4.33008877e-001],\n",
      "       [-5.01880519e-001],\n",
      "       [ 5.76512527e-002],\n",
      "       [-7.40943739e-001],\n",
      "       [ 2.99024142e-001],\n",
      "       [-1.36484921e+000],\n",
      "       [-5.08624929e-001],\n",
      "       [-2.37674207e-001],\n",
      "       [ 2.64994879e-001],\n",
      "       [ 2.93934071e-001],\n",
      "       [ 3.03069754e-171],\n",
      "       [-5.54446071e-001],\n",
      "       [ 8.14592569e-005],\n",
      "       [-3.57510972e-001],\n",
      "       [ 2.51223864e-014],\n",
      "       [ 5.93358507e-001],\n",
      "       [ 4.82465927e-001],\n",
      "       [ 3.94121051e-001],\n",
      "       [ 4.42371613e-172],\n",
      "       [ 3.85322761e-001],\n",
      "       [ 3.08124572e-001],\n",
      "       [-1.56235462e+000],\n",
      "       [-9.47901837e-001],\n",
      "       [-1.60994899e-001],\n",
      "       [-1.76434674e+000],\n",
      "       [-5.07575009e-001],\n",
      "       [ 1.72004838e-010],\n",
      "       [ 2.05877771e-170],\n",
      "       [-1.69184414e-173],\n",
      "       [ 3.79478870e-001],\n",
      "       [ 6.97697449e-001],\n",
      "       [-4.94307044e-001],\n",
      "       [-1.10133003e+000],\n",
      "       [ 3.58872206e-001],\n",
      "       [-8.18105035e-001],\n",
      "       [-9.40078856e-001],\n",
      "       [-1.37003291e-001],\n",
      "       [-1.20693972e-001],\n",
      "       [-5.85638683e-001],\n",
      "       [ 4.39659114e-001],\n",
      "       [ 8.10861458e-002],\n",
      "       [-1.78272119e-009],\n",
      "       [-1.59079361e-001],\n",
      "       [ 5.62042621e-003],\n",
      "       [ 4.53073716e-135],\n",
      "       [-8.45247059e-002],\n",
      "       [-2.27390229e-173],\n",
      "       [-1.77453610e-002],\n",
      "       [ 1.33277424e-158],\n",
      "       [-6.07849639e-174],\n",
      "       [ 3.64886958e-002],\n",
      "       [ 2.14670837e-001],\n",
      "       [ 7.14452739e-001],\n",
      "       [-1.03556673e-145],\n",
      "       [ 1.56960611e-001],\n",
      "       [-1.22053813e+000],\n",
      "       [-1.23329724e-001],\n",
      "       [-6.68195677e-001],\n",
      "       [-2.11221200e-001],\n",
      "       [-1.44757502e+000],\n",
      "       [-4.01726592e-001],\n",
      "       [ 3.77902449e-001],\n",
      "       [-2.90566059e+000],\n",
      "       [ 6.01439358e-001],\n",
      "       [ 3.12699544e-001]])]\n"
     ]
    }
   ],
   "source": [
    "def convert_class(raw, num_class=2):\n",
    "    raw = int(raw)\n",
    "    if num_class == 2:\n",
    "        if raw<=10: return 0\n",
    "        else: return 1\n",
    "    elif num_class == 3:\n",
    "        if raw <= 8:\n",
    "            return 0\n",
    "        elif 9<=raw<=10:\n",
    "            return 1\n",
    "        elif 11<=raw:\n",
    "            return 2\n",
    "    elif num_class == 29:\n",
    "        return raw\n",
    "\n",
    "def load_abalone(addsex=False, num_class=2):\n",
    "    X, y = [], []\n",
    "    with open('abalone.data', 'r') as fin:\n",
    "        for line in fin:\n",
    "            atts = line[:-1].split(\",\")\n",
    "            if not addsex:\n",
    "                X.append(atts[1:-1])\n",
    "            else:\n",
    "                sex = atts[0]\n",
    "                if sex == \"M\": sex = 0\n",
    "                elif sex==\"I\": sex = 1\n",
    "                elif sex==\"F\": sex = 2\n",
    "                else: sex = 3\n",
    "                \n",
    "                X.append([sex] + atts[1:-1])\n",
    "            y.append(convert_class(atts[-1], num_class))\n",
    "    X = np.array(X, dtype=float)\n",
    "    return X, y\n",
    "\n",
    "X, y = load_abalone(addsex=False, num_class=2)\n",
    "print('X:', X.shape, 'y:', set(y))\n",
    "\n",
    "clf = MLPClassifier(max_iter=2000)\n",
    "clf.fit(X,y)\n",
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.(b) \n",
    "(Harder) Change the size and/or number of hidden layers. How are the resulting weights affected? Can you discern any relationship between the weights for layers of varying sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.76084391e-01, -1.13947094e-01, -1.34522862e-01,\n",
      "         8.95557788e-01, -6.08703456e-01, -1.30231565e-02,\n",
      "         2.31100192e-01, -5.94617879e-02, -3.34515546e-01,\n",
      "        -9.37085264e-02],\n",
      "       [ 8.46616908e-02, -2.60303015e-01, -2.26368975e-01,\n",
      "         6.40072301e-01,  5.43843139e-01, -4.64420425e-02,\n",
      "         2.01323783e-01, -3.31400500e-03,  4.90019264e-01,\n",
      "        -2.27951739e-01],\n",
      "       [-3.61717586e-01,  7.03168093e-01,  7.24304751e-01,\n",
      "        -5.93953680e-01,  3.62272864e-01,  1.41123756e-05,\n",
      "         4.26361947e-01, -5.16114856e-03,  1.90923783e-01,\n",
      "         1.78550563e-01],\n",
      "       [-6.98956889e-01,  4.00416081e-01,  3.35867411e-01,\n",
      "        -2.73298097e-01, -4.95713229e-01,  1.76467202e-12,\n",
      "         4.58799692e-02, -1.29637374e-01, -1.33141264e-01,\n",
      "        -2.09096557e-01]]), array([[ 8.43171933e-03,  1.78581510e-01,  4.86077367e-01,\n",
      "        -2.52841651e-02, -1.00125552e+00,  3.71859576e-03,\n",
      "        -5.03138632e-02,  6.22128033e-01,  1.68278243e-02,\n",
      "        -6.39945929e-01],\n",
      "       [-5.11727671e-02,  6.20942388e-01,  2.08338130e-02,\n",
      "         1.24499483e-03,  1.02668728e+00, -1.15440221e-07,\n",
      "         2.90458675e-02,  9.83787522e-03, -2.30990700e-08,\n",
      "         8.06334352e-01],\n",
      "       [-3.67760033e-02,  5.95060868e-01, -1.52027478e-03,\n",
      "        -3.28652911e-03,  5.88409811e-01, -3.49899824e-02,\n",
      "        -8.62605621e-02, -8.65577837e-02, -6.61835548e-03,\n",
      "         7.43115278e-01],\n",
      "       [-1.97915710e-02, -2.10626323e-01, -8.52336984e-02,\n",
      "        -6.92732887e-03, -5.66081023e-01, -4.10969586e-02,\n",
      "        -1.17180528e-01,  5.41254089e-01, -1.01400396e-01,\n",
      "        -2.16454456e-01],\n",
      "       [ 9.09826804e-03, -4.47424229e-01,  2.63817815e-01,\n",
      "        -1.87336112e-03,  2.37952855e-01,  3.59401358e-04,\n",
      "         8.20332356e-03, -3.44666242e-01, -4.33755480e-16,\n",
      "        -2.68675043e-01],\n",
      "       [ 8.87090292e-02, -1.72247659e-02, -2.03023029e-02,\n",
      "         4.87631049e-10,  4.08336556e-02,  6.29294404e-02,\n",
      "         5.25677740e-02,  9.14070129e-05,  1.93177578e-02,\n",
      "         5.32034980e-03],\n",
      "       [ 1.67984317e-02, -2.14929659e-01, -3.78919167e-01,\n",
      "        -2.22974162e-02,  1.33897852e-01, -6.54365784e-02,\n",
      "        -8.85541784e-03,  2.90753101e-01,  2.63248014e-02,\n",
      "         6.70683510e-01],\n",
      "       [-5.60979674e-02, -1.77144684e-04,  6.28653690e-03,\n",
      "         7.00261978e-02, -3.86659899e-04,  3.87054338e-02,\n",
      "        -8.40256531e-06, -1.98032982e-03, -3.77377703e-02,\n",
      "        -3.97754815e-03],\n",
      "       [ 6.81906967e-02,  6.92814935e-02,  5.07911512e-01,\n",
      "         8.48702740e-02, -2.61276017e-01, -4.43401399e-03,\n",
      "         4.37583975e-10, -5.23372768e-01, -5.59536037e-02,\n",
      "        -4.06752603e-02],\n",
      "       [-3.59233623e-07,  1.54152503e-02, -7.64555134e-07,\n",
      "        -9.96156660e-02, -9.65908170e-02,  1.78811632e-02,\n",
      "        -1.88047333e-02, -1.89946169e-03, -4.86300017e-02,\n",
      "        -8.76127987e-03]]), array([[-1.79582083e-01,  9.75090198e-04,  1.17242918e-03,\n",
      "         2.70478611e-03],\n",
      "       [-3.01194628e-01, -6.86391995e-01,  1.03771911e+00,\n",
      "         8.79321182e-01],\n",
      "       [-4.87424797e-02, -2.76866059e-01, -4.54313671e-01,\n",
      "         2.95824296e-01],\n",
      "       [-1.07697879e-05,  1.38143894e-02,  4.37181836e-04,\n",
      "         3.82153440e-06],\n",
      "       [-9.63759813e-01,  8.50049510e-02,  9.57894765e-01,\n",
      "         8.69075501e-01],\n",
      "       [ 1.72029361e-01,  2.52071280e-04, -1.12945757e-02,\n",
      "        -1.05095059e-03],\n",
      "       [ 2.36792981e-15, -4.14278256e-04,  1.83251348e-01,\n",
      "         1.05817553e-01],\n",
      "       [-1.76480422e-02,  7.89229287e-01, -3.07819999e-01,\n",
      "        -1.88776039e-01],\n",
      "       [ 1.40380651e-01, -5.95856121e-02,  1.47247639e-07,\n",
      "         1.10755199e-01],\n",
      "       [ 1.09467213e+00,  2.43684075e-01,  1.03334664e+00,\n",
      "         1.74017942e-01]]), array([[-1.2268309 ,  0.32791031, -1.33946947],\n",
      "       [ 1.06032716,  0.28808582, -0.53013866],\n",
      "       [-1.21196457, -0.36801478,  0.37830123],\n",
      "       [-0.6682655 , -0.87186062,  0.90327674]])]\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=[10, 10, 4], max_iter=2000)\n",
    "#this way we don't cheat read more on pipelines https://scikit-learn.org/stable/modules/compose.html\n",
    "clf.fit(X, y)\n",
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4. \n",
    "There are a couple of different tune-able parameters for the MLPClassifier , mostly dealing with the weight optimisation — however, it is often worthwhile to tune the Regularisation parameter (α).\n",
    "### Exercise 4.(a) \n",
    "Try varying orders of α between 10 and 10 −5 for a Multilayer Perceptron built on the two-class `Abalone` data. How much variance in cross-validation accuracy do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-07, 1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]\n",
      "alpha: 1e-07 mean_acc: 0.9666666666666668 standard_dev_acc: 0.029814239699997188\n",
      "alpha: 1e-06 mean_acc: 0.9666666666666668 standard_dev_acc: 0.029814239699997188\n",
      "alpha: 1e-05 mean_acc: 0.9666666666666668 standard_dev_acc: 0.029814239699997188\n",
      "alpha: 0.0001 mean_acc: 0.9666666666666668 standard_dev_acc: 0.029814239699997188\n",
      "alpha: 0.001 mean_acc: 0.9600000000000002 standard_dev_acc: 0.024944382578492935\n",
      "alpha: 0.01 mean_acc: 0.96 standard_dev_acc: 0.024944382578492935\n",
      "alpha: 0.1 mean_acc: 0.9666666666666668 standard_dev_acc: 0.029814239699997188\n",
      "alpha: 1.0 mean_acc: 0.9666666666666668 standard_dev_acc: 0.029814239699997188\n",
      "alpha: 10.0 mean_acc: 0.9466666666666665 standard_dev_acc: 0.03399346342395189\n"
     ]
    }
   ],
   "source": [
    "alphas = [np.power(10.0, i) for i in range(-7, 2)]\n",
    "print(alphas)\n",
    "\n",
    "for alpha in alphas:\n",
    "    clf = MLPClassifier(max_iter=2000, alpha=alpha)\n",
    "    pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5)\n",
    "    print('alpha: {} mean_acc: {} standard_dev_acc: {}'.format(alpha, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.(b) \n",
    "Read up on the `GridSearchCV` utility, to help you in tuning the performance of the *Multilayer Perceptron*. Split the data into a training–and–tuning partition, and a test partition. What is the value of the regularisation parameter that `GridSearchCV` comes up with? How does the test accuracy compare to the default (un-tuned) `MLPClassifier` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP acc without tuning: 1.0\n",
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=2)]: Done  54 out of  54 | elapsed:   24.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params {'alpha': 1e-05, 'hidden_layer_sizes': [10, 10]}\n",
      "acc with best params: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_devtest, y_train, y_devtest = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_devtest, y_devtest, test_size=0.5, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('MLP acc without tuning:', clf.score(X_test, y_test))\n",
    "\n",
    "hidden_sizes = [[100], [10, 10]]\n",
    "#arguments of MLPClassifier and a list of values for them to search and find the best.\n",
    "param_grid = {'alpha': alphas, 'hidden_layer_sizes':hidden_sizes}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=clf,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=2,\n",
    "                  verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_params = gs.best_params_\n",
    "print('best_params', best_params)\n",
    "clf = MLPClassifier(max_iter=2000, **best_params)\n",
    "clf.fit(X_train, y_train)\n",
    "print('acc with best params:', clf.score(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
