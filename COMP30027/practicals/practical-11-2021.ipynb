{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Week 11 - Practical Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:  You will need the newer (18.1) build of `scikit-learn` for its neural network support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 1.\n",
    "The Multilayer Perceptron is available from (newer builds of) `scikit-learn` as `sklearn.neural_network.MLPClassifier`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.(a) \n",
    "Build a default Multilayer Perceptron to classify the `Iris` data. Evaluate its cross-validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print('X:', X.shape, 'y:', set(y))\n",
    "\n",
    "\n",
    "clf = MLPClassifier(max_iter=...)\n",
    "\n",
    "print('corss-val acc:', np.mean(cross_val_score(...)))\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.(b) \n",
    "Check the `coefs_` and `n_layers_` attributes of the fitted classifier to examine the resulting neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.coefs_)\n",
    "print('parameter shapes:',...)\n",
    "print('num layers:', clf.n_layers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.\n",
    "One important issue with this Multilayer Perceptron is that it is sensitive to the scale of the input attribute values.\n",
    "### Exercise 2.(a) \n",
    "Read up on the `StandardScaler` , and re-scale the `Iris` data so that each attribute has a *mean* of 0 and a *variance* of 1. Evaluate and examine the resulting neural network built on the re-scaled data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "clf = MLPClassifier(max_iter=2000)\n",
    "\n",
    "\n",
    "print('Corss-val standardised features acc:', np.mean(...)) \n",
    "#it is cheating because the mean and variance are estimated using both training and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.(c) \n",
    "*(Harder)* Calculating the _mean_ and _variance_ on the entire data set (before splitting into train/test sets) is cheating slightly. Write a re-scale function that calculates the scaling factors for the training data, and applies the scaler to the test data. Then, write a wrapper function that uses this to cross-validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(max_iter=2000)\n",
    "\n",
    "pipeline = Pipeline([('transformer',...), ('estimator', ...)])\n",
    "#this way we don't cheat read more on pipelines https://scikit-learn.org/stable/modules/compose.html\n",
    "\n",
    "print('corss-val noncheating standardised features acc:', np.mean(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.\n",
    "You can coerce the Multilayer Perceptron to have specifically–sized hidden layers using the *hidden_layer_sizes* parameter.\n",
    "### Exercise 3.(a) \n",
    "Train a Multilayer Perceptron on the two-class `Abalone` data, and examine the resulting neural\n",
    "network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_class(raw, num_class=2):\n",
    "    raw = int(raw)\n",
    "    if num_class == 2:\n",
    "        if raw<=10: return 0\n",
    "        else: return 1\n",
    "    elif num_class == 3:\n",
    "        if raw <= 8:\n",
    "            return 0\n",
    "        elif 9<=raw<=10:\n",
    "            return 1\n",
    "        elif 11<=raw:\n",
    "            return 2\n",
    "    elif num_class == 29:\n",
    "        return raw\n",
    "\n",
    "def load_abalone(addsex=False, num_class=2):\n",
    "    X, y = [], []\n",
    "    with open('abalone.data', 'r') as fin:\n",
    "        for line in fin:\n",
    "            atts = line[:-1].split(\",\")\n",
    "            if not addsex:\n",
    "                X.append(atts[1:-1])\n",
    "            else:\n",
    "                sex = atts[0]\n",
    "                if sex == \"M\": sex = 0\n",
    "                elif sex==\"I\": sex = 1\n",
    "                elif sex==\"F\": sex = 2\n",
    "                else: sex = 3\n",
    "                \n",
    "                X.append([sex] + atts[1:-1])\n",
    "            y.append(convert_class(atts[-1], num_class))\n",
    "    X = np.array(X, dtype=float)\n",
    "    return X, y\n",
    "\n",
    "X, y = load_abalone(addsex=False, num_class=2)\n",
    "print('X:', X.shape, 'y:', set(y))\n",
    "\n",
    "clf = ...\n",
    "clf.fit(X,y)\n",
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.(b) \n",
    "*(Harder)* Change the size and/or number of hidden layers. How are the resulting weights affected? Can you discern any relationship between the weights for layers of varying sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=..., max_iter=2000)\n",
    "#this way we don't cheat read more on pipelines https://scikit-learn.org/stable/modules/compose.html\n",
    "clf.fit(X, y)\n",
    "print(clf.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4. \n",
    "There are a couple of different tune-able parameters for the MLPClassifier , mostly dealing with the weight optimisation — however, it is often worthwhile to tune the **Regularisation parameter (α)**.\n",
    "### Exercise 4.(a) \n",
    "Try varying orders of α between 10 and 10 −5 for a Multilayer Perceptron built on the two-class `Abalone` data. How much variance in cross-validation accuracy do you observe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [np.power(10.0, i) for i in range(-7, 2)]\n",
    "print(alphas)\n",
    "\n",
    "for alpha in alphas:\n",
    "    clf = MLPClassifier(max_iter=2000, alpha=...)\n",
    "    pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])\n",
    "    scores = cross_val_score(...)\n",
    "    print('alpha: {} mean_acc: {} standard_dev_acc: {}'.format(alpha, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.(b) \n",
    "Read up on the `GridSearchCV` utility, to help you in tuning the performance of the *Multilayer Perceptron*. Split the data into a training–and–tuning partition, and a test partition. What is the value of the regularisation parameter that `GridSearchCV` comes up with? How does the test accuracy compare to the default (un-tuned) `MLPClassifier` ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_devtest, y_train, y_devtest = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_devtest, y_devtest, test_size=0.5, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('MLP acc without tuning:', clf.score(X_test, y_test))\n",
    "\n",
    "hidden_sizes = [[100], [10, 10]]\n",
    "#arguments of MLPClassifier and a list of values for them to search and find the best.\n",
    "param_grid = {'alpha': ..., 'hidden_layer_sizes':...}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(estimator=...,\n",
    "                  param_grid=...,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  n_jobs=2,\n",
    "                  verbose=1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "best_params = gs.best_params_\n",
    "print('best_params', best_params)\n",
    "\n",
    "clf = MLPClassifier(max_iter=2000, **best_params)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('acc with best params:', clf.score(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
